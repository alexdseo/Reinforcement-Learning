{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from gym.envs.registration import register\n",
    "import random as pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rargmax(vector):    # https://gist.github.com/stober/1943451\n",
    "    \"\"\" Argmax that chooses randomly among eligible maximum idices. \"\"\"\n",
    "    m = np.amax(vector)\n",
    "    indices = np.nonzero(vector == m)[0]\n",
    "    return pr.choice(indices)\n",
    "\n",
    "register(\n",
    "    id='FrozenLake-v3',\n",
    "    entry_point='gym.envs.toy_text:FrozenLakeEnv',\n",
    "    kwargs={'map_name' : '4x4', 'is_slippery': False}\n",
    ")\n",
    "env = gym.make('FrozenLake-v3')\n",
    "\n",
    "# Initialize table with all zeros\n",
    "Q = np.zeros([env.observation_space.n, env.action_space.n])\n",
    "# Set learning parameters\n",
    "num_episodes = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success rate: 0.9755\n",
      "Final Q-Table Values\n",
      "LEFT DOWN RIGHT UP\n",
      "[[0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 0. 0.]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Dummy Q-Learning\n",
    "# Initialize table with all zeros\n",
    "Q = np.zeros([env.observation_space.n, env.action_space.n])\n",
    "# Set learning parameters\n",
    "num_episodes = 2000\n",
    "\n",
    "# create lists to contain total rewards and steps per episode\n",
    "rList = []\n",
    "for i in range(num_episodes):\n",
    "    # Reset environment and get first new observation\n",
    "    state = env.reset()\n",
    "    rAll = 0\n",
    "    done = False\n",
    "\n",
    "    # The Q-Table learning algorithm\n",
    "    while not done:\n",
    "        action = rargmax(Q[state, :])\n",
    "\n",
    "        # Get new state and reward from environment\n",
    "        new_state, reward, done, _ = env.step(action)\n",
    "\n",
    "        # Update Q-Table with new knowledge using learning rate\n",
    "        Q[state, action] = reward + np.max(Q[new_state, :])\n",
    "\n",
    "        rAll += reward\n",
    "        state = new_state\n",
    "    rList.append(rAll)\n",
    "\n",
    "print(\"Success rate: \" + str(sum(rList) / num_episodes))\n",
    "print(\"Final Q-Table Values\")\n",
    "print(\"LEFT DOWN RIGHT UP\")\n",
    "print(Q)\n",
    "\n",
    "plt.bar(range(len(rList)), rList, color=\"blue\")\n",
    "#plt.bar(range(len(rList)), rList, color='b', alpha=0.4)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
